{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374e2ae2",
   "metadata": {},
   "source": [
    "![image.png](attachment:ad7ccc24-be80-4202-8d58-3ec6a78b4c23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa305e25",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  E-Waste Image Classification Using EfficientNetV2B0 (Transfer Learning)\n",
    "\n",
    "\n",
    "\n",
    "##  Problem Statement and Description\n",
    "\n",
    "E-waste (electronic waste) is rapidly becoming a serious environmental and health issue around the world. Proper sorting and categorization of e-waste is essential for efficient recycling and disposal, but manual classification is error-prone and labor-intensive.\n",
    "\n",
    "This project aims to build an automated e-waste classification system using artificial intelligence and machine learning. By training a deep learning model on images of different types of e-waste, we can identify and categorize them accurately.\n",
    "\n",
    "###  Goal:\n",
    "Use image classification with EfficientNetV2B0 to classify e-waste into 10 distinct categories to support better sorting and recycling automation.\n",
    "\n",
    "---\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad92d4b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##  Dataset Overview\n",
    "\n",
    "###  Dataset Name: E-Waste Image Dataset  \n",
    "###  Source:  https://www.kaggle.com/datasets/akshat103/e-waste-image-dataset \n",
    "\n",
    "Each directory contains 10 subfolders, each representing one class of e-waste:\n",
    "\n",
    "- PCB (Printed Circuit Board)\n",
    "- Player\n",
    "- Battery\n",
    "- Microwave\n",
    "- Mobile\n",
    "- Mouse\n",
    "- Printer\n",
    "- Television\n",
    "- Washing Machine\n",
    "- Keyboard\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ed029",
   "metadata": {},
   "source": [
    "![image.png](attachment:5fe4e2cd-166c-4a06-93db-01d11bd9d78a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83e4d1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "##  What is Transfer Learning?\n",
    "\n",
    "Transfer Learning: Transfer Learning is a machine learning technique where a pre-trained model developed for a specific task is reused as the starting point for a model on a different but related task. It also allows us to build accurate models in a time-saving way by starting from patterns learned when solving a different problem. This approach is beneficial when there is limited data for the new task, as the pre-trained model already has learned features that can be adapted. Transfer learning can significantly improve models' performance and efficiency in domains like computer vision and natural language processing.\n",
    "\n",
    "###  Benefits\n",
    "-  **Reduces training time** — you don't start from scratch.\n",
    "-  **Leverages learned features** from large datasets (like ImageNet).\n",
    "-  **Improves performance**, especially with limited data.\n",
    "\n",
    "---\n",
    "\n",
    "##  How Does It Work?\n",
    "\n",
    "1.  Load a pretrained model (e.g., ResNet, EfficientNet).\n",
    "2.  **Freeze** the pretrained layers (optional).\n",
    "3.  Add new layers for your custom task.\n",
    "4.  Train on your new dataset (can also fine-tune).\n",
    "\n",
    "---\n",
    "\n",
    "#  EfficientNetV2B0: Transfer Learning Backbone\n",
    "\n",
    "##  Overview\n",
    "\n",
    "EfficientNetV2 is an optimized family of models introduced by Google for efficient training and inference.\n",
    "\n",
    "###  Key Features:\n",
    "-  Fused MBConv blocks — improve training speed and GPU efficiency.\n",
    "-  Progressive learning — gradually increases input size during training.\n",
    "-  Better accuracy with fewer parameters and FLOPs.\n",
    "\n",
    "---\n",
    "\n",
    "##  Why Use EfficientNetV2B0?\n",
    " -  Lightweight - Small model size, ideal for mobile & edge devices \n",
    " -  Fast - Quick training and inference           \n",
    " -  Pretrained on ImageNet - Excellent feature extraction baseline             \n",
    " -  High Accuracy - Competitively performs even in low-resource setups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0eb7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow package\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411597f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Collecting tensorflow\n",
    "  Downloading tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
    "Collecting absl-py>=1.0.0 (from tensorflow)\n",
    "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
    "Collecting astunparse>=1.6.0 (from tensorflow)\n",
    "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
    "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
    "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
    "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
    "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
    "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
    "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
    "Collecting libclang>=13.0.0 (from tensorflow)\n",
    "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
    "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
    "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
    "Collecting packaging (from tensorflow)\n",
    "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
    "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
    "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
    "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
    "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
    "Requirement already satisfied: setuptools in c:\\users\\lenovo\\desktop\\e waste project\\.venv\\lib\\site-packages (from tensorflow) (65.5.0)\n",
    "Collecting six>=1.12.0 (from tensorflow)\n",
    "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
    "Collecting termcolor>=1.1.0 (from tensorflow)\n",
    "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
    "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
    "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
    "Collecting wrapt>=1.11.0 (from tensorflow)\n",
    "  Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
    "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
    "  Downloading grpcio-1.73.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
    "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
    "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
    "Collecting keras>=3.5.0 (from tensorflow)\n",
    "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
    "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
    "  Downloading numpy-2.1.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
    "Collecting h5py>=3.11.0 (from tensorflow)\n",
    "  Downloading h5py-3.14.0-cp311-cp311-win_amd64.whl.metadata (2.7 kB)\n",
    "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
    "  Downloading ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
    "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
    "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
    "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
    "  Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
    "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
    "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
    "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
    "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
    "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
    "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
    "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
    "  Downloading markdown-3.8.1-py3-none-any.whl.metadata (5.1 kB)\n",
    "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
    "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
    "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
    "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
    "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
    "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
    "Collecting rich (from keras>=3.5.0->tensorflow)\n",
    "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
    "Collecting namex (from keras>=3.5.0->tensorflow)\n",
    "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
    "Collecting optree (from keras>=3.5.0->tensorflow)\n",
    "  Downloading optree-0.16.0-cp311-cp311-win_amd64.whl.metadata (31 kB)\n",
    "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow)\n",
    "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
    "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
    "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
    "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.5.0->tensorflow)\n",
    "  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
    "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
    "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
    "Downloading tensorflow-2.19.0-cp311-cp311-win_amd64.whl (375.9 MB)\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 375.9/375.9 MB 3.6 MB/s eta 0:00:00\n",
    "Downloading grpcio-1.73.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.3/4.3 MB 4.0 MB/s eta 0:00:00\n",
    "Downloading ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl (209 kB)\n",
    "Downloading numpy-2.1.3-cp311-cp311-win_amd64.whl (12.9 MB)\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.9/12.9 MB 3.6 MB/s eta 0:00:00\n",
    "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
    "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
    "Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl (105 kB)\n",
    "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
    "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 3.8 MB/s eta 0:00:00\n",
    "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
    "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
    "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
    "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
    "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
    "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
    "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
    "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
    "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
    "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
    "Downloading h5py-3.14.0-cp311-cp311-win_amd64.whl (2.9 MB)\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 4.0 MB/s eta 0:00:00\n",
    "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 4.2 MB/s eta 0:00:00\n",
    "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.4/26.4 MB 3.9 MB/s eta 0:00:00\n",
    "Downloading markdown-3.8.1-py3-none-any.whl (106 kB)\n",
    "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
    "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
    "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 3.7 MB/s eta 0:00:00\n",
    "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
    "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
    "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
    "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
    "Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
    "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
    "Downloading optree-0.16.0-cp311-cp311-win_amd64.whl (314 kB)\n",
    "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
    "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
    "Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
    "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
    "Downloading optree-0.16.0-cp311-cp311-win_amd64.whl (314 kB)\n",
    "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
    "Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
    "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
    "Downloading optree-0.16.0-cp311-cp311-win_amd64.whl (314 kB)\n",
    "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
    "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
    "Downloading optree-0.16.0-cp311-cp311-win_amd64.whl (314 kB)\n",
    "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
    "Downloading optree-0.16.0-cp311-cp311-win_amd64.whl (314 kB)\n",
    "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
    "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
    "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
    "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
    "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
    "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
    "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, pygments, protobuf, packaging, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, gast, charset_normalizer, certifi, absl-py, werkzeug, requests, optree, ml-dtypes, markdown-it-py, h5py, google-pasta, astunparse, tensorboard, rich, keras, tensorflow\n",
    "Successfully installed MarkupSafe-3.0.2 absl-py-2.3.0 astunparse-1.6.3 certifi-2025.6.15 charset_normalizer-3.4.2 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.0 h5py-3.14.0 idna-3.10 keras-3.10.0 libclang-18.1.1 markdown-3.8.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.1.0 numpy-2.1.3 opt-einsum-3.4.0 optree-0.16.0 packaging-25.0 protobuf-5.29.5 pygments-2.19.1 requests-2.32.4 rich-14.0.0 six-1.17.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.1.0 typing-extensions-4.14.0 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6398f",
   "metadata": {},
   "source": [
    "###  Core Libraries\n",
    "- `tensorflow`: For deep learning model building and training.\n",
    "- `numpy`: For numerical operations and array manipulation.\n",
    "- `matplotlib.pyplot`: For plotting training curves and results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e946ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # Core TensorFlow library\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks  # Layers, model creation, optimizers, and training callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model  # For sequential model architecture and loading saved models\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetV2B0  # Pretrained EfficientNetV2B0 model for transfer learning\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input  # Preprocessing function specific to EfficientNet\n",
    "\n",
    "import numpy as np  # Numerical operations and array handling\n",
    "\n",
    "import matplotlib.pyplot as plt  # Plotting graphs and images\n",
    "\n",
    "import seaborn as sns  # Plotting graphs and images\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # Evaluation metrics for classification models\n",
    "\n",
    "import gradio as gr  # Web interface library to deploy and test ML models\n",
    "\n",
    "from PIL import Image  # For image file loading and basic image operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d0a58",
   "metadata": {},
   "source": [
    "###  Format: Folder-based image classification dataset  \n",
    "- `Train/`: Images used for training the model  \n",
    "- `Test/`: Images used for model evaluation  \n",
    "- `Validation/`: Images used to fine-tune and validate the model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e336c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath= r'C:\\Users\\Lenovo\\Desktop\\E waste project\\E-Waste classification dataset\\modified-dataset\\test'\n",
    "trainpath= r'C:\\Users\\Lenovo\\Desktop\\E waste project\\E-Waste classification dataset\\modified-dataset\\train'\n",
    "validpath = r'C:\\Users\\Lenovo\\Desktop\\E waste project\\E-Waste classification dataset\\modified-dataset\\val'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
